{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "from numpy import log, dot, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib\n",
    "#!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate logistic regression equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) log(odds) = p / 1-p\n",
    "\n",
    "2) p = e^log(odds)/ (1 + e^log(odds))\n",
    "\n",
    "3) log(odds) = mx+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Logistic_Regression():\n",
    "    def __init__(self):\n",
    "        pass   \n",
    "\n",
    "    def create_random_data(self,hm_features,obs):\n",
    "\n",
    "        X = np.ones((obs))\n",
    "\n",
    "        for i in range(hm_features):\n",
    "            xs = np.random.rand(obs)*100\n",
    "            X = np.append(X,xs)\n",
    "\n",
    "        X = np.reshape(X, (-1,obs)).transpose()\n",
    "        ys = np.random.randint(0,2,size=obs) # 2 high as it's exclusive\n",
    "        \n",
    "        return X,ys\n",
    "    \n",
    "    def sigma_fx(self,x):\n",
    "        return 1/ (1+e**-x)\n",
    "    \n",
    "    def cost_function(self,x, y,weights):\n",
    "        '''\n",
    "            Cost function in Logistic is different than Linear\n",
    "            \n",
    "            Cost(x) = -y_actual ln(y_hat) - (1-y_actual) ln(1-y_hat)\n",
    "            Easy way to remember this equation\n",
    "            When y_actual = 1 then Cost(x) = -ln(y_hat)\n",
    "            when y_actual = 0 then Cost(x) = -ln(1 - y_hat)\n",
    "            \n",
    "            this cost function is optimised using Gradient descent which \n",
    "            require derivatives\n",
    "            \n",
    "            cost(x) = x (y_hat - y)\n",
    "        '''\n",
    "        z = dot(x,weights)\n",
    "        predict_1 = -y * np.log(self.sigma_fx(z))\n",
    "        predict_0 = -(1-y) * np.log(self.sigma_fx(z))\n",
    "\n",
    "        return sum(predict_1+predict_0)/len(x)\n",
    "    \n",
    "    \n",
    "    def fit(self,x,y,epc = 3,lr=0.05):\n",
    "        weights = np.random.rand(x.shape[1]) # random weights initialised\n",
    "        loss = [] # to track of loss value\n",
    "        N = len(x) # no of samples\n",
    "        \n",
    "        for _ in range(epc):\n",
    "            #Gradient descent\n",
    "            \n",
    "            y_hat = self.sigma_fx(x.dot(weights)) # independent variables multiplied with weights\n",
    "                                                  #  values scaled by sigmoid function\n",
    "            weights = weights - (lr * (dot(x.T, y_hat - y)/N))\n",
    "            loss.append(self.cost_function(x,y,weights))\n",
    "        \n",
    "        self.weights = weights\n",
    "        \n",
    "        self.loss = loss\n",
    "        return weights, loss[-1]\n",
    "        \n",
    "    def predict_prob(self,x):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        return self.sigma_fx(x.dot(self.weights))\n",
    "    \n",
    "    def predict_class(self,x):\n",
    "        '''\n",
    "        '''\n",
    "        return [1 if i > 0.5 else 0 for i in self.sigma_fx(x.dot(self.weights))]\n",
    "    \n",
    "    def model_stats(self,y_hat,y):\n",
    "        '''\n",
    "        1) MAE -> Y_hat - y\n",
    "        2) MAPE -> (Y_hat - y)/y\n",
    "        3) R2\n",
    "        '''\n",
    "        y_mean = np.mean(y)\n",
    "        sse = sum((y_hat - y)**2)\n",
    "        ssm =sum((y_mean-y)**2)\n",
    "        return np.average(np.abs(y_hat - y)), np.mean(np.abs(y_hat - y)/y), 1 - (sse/ssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = Xx['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xx.drop(['Name','Survived','Sex'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X.copy() ; X_['Intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \\\n",
       "0         3  22.0                        1                        0   7.2500   \n",
       "1         1  38.0                        1                        0  71.2833   \n",
       "2         3  26.0                        0                        0   7.9250   \n",
       "3         1  35.0                        1                        0  53.1000   \n",
       "4         3  35.0                        0                        0   8.0500   \n",
       "..      ...   ...                      ...                      ...      ...   \n",
       "882       2  27.0                        0                        0  13.0000   \n",
       "883       1  19.0                        0                        0  30.0000   \n",
       "884       3   7.0                        1                        2  23.4500   \n",
       "885       1  26.0                        0                        0  30.0000   \n",
       "886       3  32.0                        0                        0   7.7500   \n",
       "\n",
       "     Intercept  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "882          1  \n",
       "883          1  \n",
       "884          1  \n",
       "885          1  \n",
       "886          1  \n",
       "\n",
       "[887 rows x 6 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_my_LR =  My_Logistic_Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random data generated\n",
    "X,ys = clf_my_LR.create_random_data(3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.48028579, -0.04113382, -0.37075653,  0.17132078,  0.00775823,\n",
       "         0.99083312]),\n",
       " 1.525775286428782)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_my_LR.fit(X_,ys,10000,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_my_LR.predict_class(X_); sum(clf_my_LR.predict_class(X_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.000453\n",
       "1    0.999988\n",
       "2    0.029974\n",
       "3    0.998414\n",
       "4    0.004354\n",
       "5    0.028287\n",
       "6    0.998848\n",
       "7    0.000109\n",
       "8    0.038566\n",
       "9    0.927744\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_my_LR.predict_prob(X_)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[445, 100],\n",
       "       [156, 186]], dtype=int64)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ys,clf_my_LR.predict_class(X_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = [x for x in zip(xs_0,xs_1)]\n",
    "#X = [x for x in zip(xs_0,xs_1,xs_2,xs_3)]\n",
    "#X = [xs_1] + [xs_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ys_ = ys.reshape(-1,1)\n",
    "#clf.fit(xs_0.reshape(-1,1),ys)  #temp.reshape(-1,1)\n",
    "clf.fit(X,ys)  #temp.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.00777123, -0.04229388, -0.28125379,  0.21454081,  0.00474583]]),\n",
       " array([2.9612604]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_,clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_LR_hat = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_LR_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[464,  81],\n",
       "       [184, 158]], dtype=int64)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ys,y_LR_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
